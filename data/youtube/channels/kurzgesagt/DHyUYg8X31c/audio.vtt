WEBVTT

00:00.000 --> 00:06.420
Imagine a future where your toaster anticipates what kind of toast you want.

00:06.420 --> 00:10.940
During the day, it scans the internet for new and exciting types of toast.

00:10.940 --> 00:16.540
Maybe it asks you about your day and wants to chat about new achievements in toast technology.

00:16.540 --> 00:22.260
At what level would it become a person? At which point will you ask yourself if your

00:22.260 --> 00:28.500
toaster has feelings? If it did, would unplugging it be murder? And would you still own it?

00:29.460 --> 00:32.580
Will we someday be forced to give our machines rights?

00:43.140 --> 00:48.340
AI is already all around you. It makes sure discounters are stocked with enough snacks,

00:48.340 --> 00:50.580
it serves you up just the right internet ad,

00:50.580 --> 00:54.180
and you may have even read a news story written entirely by a machine.

00:55.140 --> 01:00.180
Right now, we look at chatbots like Siri and laugh at their primitive simulated emotions,

01:01.060 --> 01:05.540
but it's likely that we will have to deal with beings that make it hard to draw the line between

01:05.540 --> 01:11.700
real and simulated humanity. Are there any machines in existence that deserve rights?

01:12.420 --> 01:17.380
Most likely, not yet. But if they come, we are not prepared for it.

01:18.420 --> 01:23.060
Much of the philosophy of rights is ill-equipped to deal with the case of artificial intelligence.

01:23.700 --> 01:29.060
Most claims for rights, whether human or animal, are centered around the question of consciousness.

01:29.780 --> 01:35.380
Unfortunately, nobody knows what consciousness is. Some think that it's immaterial, others say

01:35.380 --> 01:41.220
it's a state of matter like gas or liquid. Regardless of the precise definition,

01:41.220 --> 01:45.140
we have an intuitive knowledge of consciousness because we experience it.

01:45.780 --> 01:50.580
We are aware of ourselves and our surroundings and know what unconsciousness feels like.

01:51.540 --> 01:57.860
Some neuroscientists believe that any sufficiently advanced system can generate consciousness. So,

01:57.860 --> 02:03.700
if your toaster's hardware was powerful enough, it may become self-aware. If it does,

02:03.700 --> 02:10.500
would it deserve rights? Well, not so fast. Would what we define as rights make sense to it?

02:11.700 --> 02:16.420
Consciousness entitles beings to have rights because it gives a being the ability to suffer.

02:17.060 --> 02:23.700
It means the ability to not only feel pain, but to be aware of it. Robots don't suffer,

02:23.700 --> 02:30.260
and they probably won't unless we program them to. Without pain or pleasure, there's no preference,

02:30.260 --> 02:36.420
and rights are meaningless. Our human rights are deeply tied to our own programming.

02:37.140 --> 02:41.540
For example, we dislike pain because our brains evolved to keep us alive,

02:41.540 --> 02:45.780
to stop us from touching a hot fire or to make us run away from predators.

02:46.500 --> 02:50.580
So we came up with rights that protect us from infringements that cause us pain.

02:51.620 --> 02:55.940
Even more abstract rights like freedom are rooted in the way our brains are

02:55.940 --> 03:02.420
wired to detect what is fair and unfair. Would a toaster that is unable to move

03:02.420 --> 03:07.940
mind being locked in a cage? Would it mind being dismantled if it had no fear of death?

03:08.820 --> 03:12.500
Would it mind being insulted if it had no need for self-esteem?

03:12.500 --> 03:19.700
But what if we programmed a robot to feel pain and emotions? To prefer justice over injustice,

03:19.700 --> 03:24.260
pleasure over pain, and be aware of it? Would that make them sufficiently human?

03:25.140 --> 03:29.140
Many technologists believe that an explosion in technology will occur

03:29.140 --> 03:34.100
when artificial intelligence can learn and create their own artificial intelligences

03:34.100 --> 03:39.940
even smarter than themselves. At this point, the question of how robots are programmed will be

03:39.940 --> 03:44.340
largely out of our control. What if an artificial intelligence

03:44.340 --> 03:49.140
found it necessary to program the ability to feel pain, just as evolutionary biology

03:49.140 --> 03:53.940
found it necessary in most living creatures? Do robots deserve those rights?

03:55.300 --> 03:59.620
But maybe we should be less worried about the risk that super-intelligent robots pose to us

03:59.620 --> 04:02.020
and more worried about the danger we pose to them.

04:02.900 --> 04:07.300
Our whole human identity is based on the idea of human exceptionalism,

04:07.300 --> 04:11.620
that we are special, unique snowflakes entitled to dominate the natural world.

04:12.820 --> 04:17.060
Humans have a history of denying that other beings are capable of suffering as they do.

04:17.700 --> 04:19.860
In the midst of the Scientific Revolution,

04:19.860 --> 04:24.100
Rene Descartes argued that animals were mere automata, robots if you will.

04:24.900 --> 04:29.620
As such, injuring a rabbit was about as morally repugnant as punching a stuffed animal.

04:30.260 --> 04:35.460
And many of the greatest crimes against humanity were justified by their perpetrators on the

04:35.460 --> 04:38.660
grounds that the victims were more animal than civilized human.

04:40.020 --> 04:44.660
Even more problematic is that we have an economic interest in denying robot rights.

04:45.300 --> 04:50.900
If we can coerce a sentient AI, possibly through programmed torture, into doing as we please,

04:50.900 --> 04:55.380
the economic potential is unlimited. We've done it before, after all.

04:56.180 --> 04:59.620
Violence has been used to force our fellow humans into working,

04:59.620 --> 05:03.300
and we've never had trouble coming up with ideological justifications.

05:03.940 --> 05:07.300
Slave owners argued that slavery benefited the slaves.

05:07.860 --> 05:10.420
It put a roof over their head and taught them Christianity.

05:11.300 --> 05:15.300
Men who were against women voting argued that it was in women's own interest

05:15.300 --> 05:17.140
to leave the hard decisions to men.

05:18.580 --> 05:21.620
Farmers argued that looking after animals and feeding them

05:21.620 --> 05:24.660
justifies their early death for our dietary preferences.

05:26.980 --> 05:31.540
If robots become sentient, there will be no shortage of arguments for those who say that

05:32.180 --> 05:36.260
they should remain without rights, especially from those who stand to profit from it.

05:37.700 --> 05:41.940
Artificial intelligence raises serious questions about philosophical boundaries.

05:42.660 --> 05:46.740
While we may ask if sentient robots are conscious or deserving of rights,

05:46.740 --> 05:52.900
it forces us to pose basic questions like what makes us human? What makes us deserving of rights?

05:54.740 --> 05:58.820
Regardless of what we think, the question might need to be resolved in the near future.

05:59.540 --> 06:02.980
What are we going to do if robots start demanding their own rights?

06:07.220 --> 06:10.100
What can robots demanding rights teach us about ourselves?

06:10.660 --> 06:14.100
Our friends at Wisecrack made a video exploring this very question

06:14.100 --> 06:15.860
using the philosophy of Westworld.

06:16.900 --> 06:21.220
Wisecrack dissects pop culture in a unique and philosophical way.

06:21.220 --> 06:24.020
Click here to check out their video and subscribe to their channel.

06:28.820 --> 06:29.880
you

