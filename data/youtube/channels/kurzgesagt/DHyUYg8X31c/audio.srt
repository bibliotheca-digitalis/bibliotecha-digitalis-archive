1
00:00:00,000 --> 00:00:06,420
Imagine a future where your toaster anticipates what kind of toast you want.

2
00:00:06,420 --> 00:00:10,940
During the day, it scans the internet for new and exciting types of toast.

3
00:00:10,940 --> 00:00:16,540
Maybe it asks you about your day and wants to chat about new achievements in toast technology.

4
00:00:16,540 --> 00:00:22,260
At what level would it become a person? At which point will you ask yourself if your

5
00:00:22,260 --> 00:00:28,500
toaster has feelings? If it did, would unplugging it be murder? And would you still own it?

6
00:00:29,460 --> 00:00:32,580
Will we someday be forced to give our machines rights?

7
00:00:43,140 --> 00:00:48,340
AI is already all around you. It makes sure discounters are stocked with enough snacks,

8
00:00:48,340 --> 00:00:50,580
it serves you up just the right internet ad,

9
00:00:50,580 --> 00:00:54,180
and you may have even read a news story written entirely by a machine.

10
00:00:55,140 --> 00:01:00,180
Right now, we look at chatbots like Siri and laugh at their primitive simulated emotions,

11
00:01:01,060 --> 00:01:05,540
but it's likely that we will have to deal with beings that make it hard to draw the line between

12
00:01:05,540 --> 00:01:11,700
real and simulated humanity. Are there any machines in existence that deserve rights?

13
00:01:12,420 --> 00:01:17,380
Most likely, not yet. But if they come, we are not prepared for it.

14
00:01:18,420 --> 00:01:23,060
Much of the philosophy of rights is ill-equipped to deal with the case of artificial intelligence.

15
00:01:23,700 --> 00:01:29,060
Most claims for rights, whether human or animal, are centered around the question of consciousness.

16
00:01:29,780 --> 00:01:35,380
Unfortunately, nobody knows what consciousness is. Some think that it's immaterial, others say

17
00:01:35,380 --> 00:01:41,220
it's a state of matter like gas or liquid. Regardless of the precise definition,

18
00:01:41,220 --> 00:01:45,140
we have an intuitive knowledge of consciousness because we experience it.

19
00:01:45,780 --> 00:01:50,580
We are aware of ourselves and our surroundings and know what unconsciousness feels like.

20
00:01:51,540 --> 00:01:57,860
Some neuroscientists believe that any sufficiently advanced system can generate consciousness. So,

21
00:01:57,860 --> 00:02:03,700
if your toaster's hardware was powerful enough, it may become self-aware. If it does,

22
00:02:03,700 --> 00:02:10,500
would it deserve rights? Well, not so fast. Would what we define as rights make sense to it?

23
00:02:11,700 --> 00:02:16,420
Consciousness entitles beings to have rights because it gives a being the ability to suffer.

24
00:02:17,060 --> 00:02:23,700
It means the ability to not only feel pain, but to be aware of it. Robots don't suffer,

25
00:02:23,700 --> 00:02:30,260
and they probably won't unless we program them to. Without pain or pleasure, there's no preference,

26
00:02:30,260 --> 00:02:36,420
and rights are meaningless. Our human rights are deeply tied to our own programming.

27
00:02:37,140 --> 00:02:41,540
For example, we dislike pain because our brains evolved to keep us alive,

28
00:02:41,540 --> 00:02:45,780
to stop us from touching a hot fire or to make us run away from predators.

29
00:02:46,500 --> 00:02:50,580
So we came up with rights that protect us from infringements that cause us pain.

30
00:02:51,620 --> 00:02:55,940
Even more abstract rights like freedom are rooted in the way our brains are

31
00:02:55,940 --> 00:03:02,420
wired to detect what is fair and unfair. Would a toaster that is unable to move

32
00:03:02,420 --> 00:03:07,940
mind being locked in a cage? Would it mind being dismantled if it had no fear of death?

33
00:03:08,820 --> 00:03:12,500
Would it mind being insulted if it had no need for self-esteem?

34
00:03:12,500 --> 00:03:19,700
But what if we programmed a robot to feel pain and emotions? To prefer justice over injustice,

35
00:03:19,700 --> 00:03:24,260
pleasure over pain, and be aware of it? Would that make them sufficiently human?

36
00:03:25,140 --> 00:03:29,140
Many technologists believe that an explosion in technology will occur

37
00:03:29,140 --> 00:03:34,100
when artificial intelligence can learn and create their own artificial intelligences

38
00:03:34,100 --> 00:03:39,940
even smarter than themselves. At this point, the question of how robots are programmed will be

39
00:03:39,940 --> 00:03:44,340
largely out of our control. What if an artificial intelligence

40
00:03:44,340 --> 00:03:49,140
found it necessary to program the ability to feel pain, just as evolutionary biology

41
00:03:49,140 --> 00:03:53,940
found it necessary in most living creatures? Do robots deserve those rights?

42
00:03:55,300 --> 00:03:59,620
But maybe we should be less worried about the risk that super-intelligent robots pose to us

43
00:03:59,620 --> 00:04:02,020
and more worried about the danger we pose to them.

44
00:04:02,900 --> 00:04:07,300
Our whole human identity is based on the idea of human exceptionalism,

45
00:04:07,300 --> 00:04:11,620
that we are special, unique snowflakes entitled to dominate the natural world.

46
00:04:12,820 --> 00:04:17,060
Humans have a history of denying that other beings are capable of suffering as they do.

47
00:04:17,700 --> 00:04:19,860
In the midst of the Scientific Revolution,

48
00:04:19,860 --> 00:04:24,100
Rene Descartes argued that animals were mere automata, robots if you will.

49
00:04:24,900 --> 00:04:29,620
As such, injuring a rabbit was about as morally repugnant as punching a stuffed animal.

50
00:04:30,260 --> 00:04:35,460
And many of the greatest crimes against humanity were justified by their perpetrators on the

51
00:04:35,460 --> 00:04:38,660
grounds that the victims were more animal than civilized human.

52
00:04:40,020 --> 00:04:44,660
Even more problematic is that we have an economic interest in denying robot rights.

53
00:04:45,300 --> 00:04:50,900
If we can coerce a sentient AI, possibly through programmed torture, into doing as we please,

54
00:04:50,900 --> 00:04:55,380
the economic potential is unlimited. We've done it before, after all.

55
00:04:56,180 --> 00:04:59,620
Violence has been used to force our fellow humans into working,

56
00:04:59,620 --> 00:05:03,300
and we've never had trouble coming up with ideological justifications.

57
00:05:03,940 --> 00:05:07,300
Slave owners argued that slavery benefited the slaves.

58
00:05:07,860 --> 00:05:10,420
It put a roof over their head and taught them Christianity.

59
00:05:11,300 --> 00:05:15,300
Men who were against women voting argued that it was in women's own interest

60
00:05:15,300 --> 00:05:17,140
to leave the hard decisions to men.

61
00:05:18,580 --> 00:05:21,620
Farmers argued that looking after animals and feeding them

62
00:05:21,620 --> 00:05:24,660
justifies their early death for our dietary preferences.

63
00:05:26,980 --> 00:05:31,540
If robots become sentient, there will be no shortage of arguments for those who say that

64
00:05:32,180 --> 00:05:36,260
they should remain without rights, especially from those who stand to profit from it.

65
00:05:37,700 --> 00:05:41,940
Artificial intelligence raises serious questions about philosophical boundaries.

66
00:05:42,660 --> 00:05:46,740
While we may ask if sentient robots are conscious or deserving of rights,

67
00:05:46,740 --> 00:05:52,900
it forces us to pose basic questions like what makes us human? What makes us deserving of rights?

68
00:05:54,740 --> 00:05:58,820
Regardless of what we think, the question might need to be resolved in the near future.

69
00:05:59,540 --> 00:06:02,980
What are we going to do if robots start demanding their own rights?

70
00:06:07,220 --> 00:06:10,100
What can robots demanding rights teach us about ourselves?

71
00:06:10,660 --> 00:06:14,100
Our friends at Wisecrack made a video exploring this very question

72
00:06:14,100 --> 00:06:15,860
using the philosophy of Westworld.

73
00:06:16,900 --> 00:06:21,220
Wisecrack dissects pop culture in a unique and philosophical way.

74
00:06:21,220 --> 00:06:24,020
Click here to check out their video and subscribe to their channel.

75
00:06:28,820 --> 00:06:29,880
you

