1
00:00:00,000 --> 00:00:20,960
Yeah, I know Jon and I have, have you watched Nickatine2's recent videos on ethics where

2
00:00:20,960 --> 00:00:22,560
he's sort of battling himself?

3
00:00:22,560 --> 00:00:24,120
Yeah, I like that.

4
00:00:24,120 --> 00:00:28,680
I mean that's, that's brilliant, the almost schizophrenic multi-personality I think is

5
00:00:28,680 --> 00:00:35,560
a good, just underlying kind of way to look at things, it's more complexity than initially

6
00:00:35,560 --> 00:00:38,200
things seem to be, even in ourselves, so.

7
00:00:38,200 --> 00:00:45,200
So yeah, I guess we could start with, with ethics, I mean I know you, you're an atheist

8
00:00:45,200 --> 00:00:51,240
and you obviously think that there's a way to preserve morality and ethics independent

9
00:00:51,240 --> 00:00:53,440
of any theological worldview, right?

10
00:00:53,440 --> 00:00:56,080
Yeah, I think so.

11
00:00:56,080 --> 00:01:00,920
So how do you, how do you ground your ethical system, granted that there's some ambiguity

12
00:01:00,920 --> 00:01:05,520
there for you in light of these last two videos, but, you know, how do you approach the thing?

13
00:01:05,520 --> 00:01:09,440
Well, I mean I know you hate doing this, but suppose we were to start in sort of a place

14
00:01:09,440 --> 00:01:17,480
of Cartesian skepticism, where we, where we know what it feels like to have desires, to

15
00:01:17,480 --> 00:01:26,480
feel pleasure, to feel pain, and we can infer that other people have similar sensations,

16
00:01:26,480 --> 00:01:31,520
that other people have desires and wishes and can feel pain and suffering just as we

17
00:01:31,520 --> 00:01:37,800
can, and we can empathize with them, we can, we have the imaginative power to put ourselves

18
00:01:37,800 --> 00:01:42,960
in their place and act in a way that benefits not only our own selves, our own interests,

19
00:01:42,960 --> 00:01:45,120
but also the interests of other minds.

20
00:01:45,120 --> 00:01:46,980
Right, yeah.

21
00:01:46,980 --> 00:01:50,580
So empathy then would be the basis of, of morality?

22
00:01:50,580 --> 00:01:52,380
Yeah, that's pretty much it.

23
00:01:52,380 --> 00:01:53,380
Okay.

24
00:01:53,380 --> 00:01:57,220
And you know, you said we have to begin with a sort of Cartesian skepticism to write.

25
00:01:57,220 --> 00:01:58,980
We don't have to, but we could.

26
00:01:58,980 --> 00:01:59,980
Right.

27
00:01:59,980 --> 00:02:05,220
Well, I mean, it almost seemed to me though that it's sort of, while Descartes sort of

28
00:02:05,220 --> 00:02:11,060
skepticism involves reflection, I think empathy with others is sort of immediate, you know,

29
00:02:11,060 --> 00:02:14,940
when you see someone who's in pain, you just feel their pain, you know, not literally.

30
00:02:14,940 --> 00:02:15,940
Yeah, yeah, yeah.

31
00:02:15,940 --> 00:02:16,940
I mean, it's much more immediate than that.

32
00:02:16,940 --> 00:02:17,940
You're right.

33
00:02:17,940 --> 00:02:21,300
I mean, Descartes' skepticism is, I mean, I don't, he didn't even believe that for a

34
00:02:21,300 --> 00:02:22,300
second.

35
00:02:22,300 --> 00:02:23,300
That was just his method.

36
00:02:23,300 --> 00:02:29,100
You know, that's something you only come to through thinking about it a lot.

37
00:02:29,100 --> 00:02:34,140
Immediately, there's no question that other people have experiences like your own.

38
00:02:34,140 --> 00:02:35,140
Right.

39
00:02:35,140 --> 00:02:36,140
Yeah.

40
00:02:36,140 --> 00:02:37,140
I would hope not.

41
00:02:37,140 --> 00:02:38,140
But, you know.

42
00:02:38,140 --> 00:02:39,140
Yeah, I would hope not.

43
00:02:39,140 --> 00:02:44,260
But there's something to reflecting on it, you know, after all said and done, after the

44
00:02:44,260 --> 00:02:48,380
immediate event is done, you have time to go back and sip a little wine and reflect

45
00:02:48,380 --> 00:02:49,380
on it.

46
00:02:49,380 --> 00:02:53,700
Is there something to that dimension that complexifies and matures your empathy?

47
00:02:53,700 --> 00:02:56,140
Is it, would you say that's accurate, Nick?

48
00:02:56,140 --> 00:02:57,140
Yeah.

49
00:02:57,140 --> 00:02:58,140
Yeah.

50
00:02:58,140 --> 00:02:59,140
Yeah.

51
00:02:59,140 --> 00:03:03,980
Well, I mean, maybe we could just make a distinction between ethics and morality where ethics is

52
00:03:03,980 --> 00:03:08,300
sort of the practical action in the day-to-day world and then when you come up with a moral

53
00:03:08,300 --> 00:03:12,360
philosophy, that's when you start reflecting on, wait a minute, maybe that ethical decision

54
00:03:12,360 --> 00:03:18,320
I made in the heat of battle wasn't exactly as moral as it could have been.

55
00:03:18,320 --> 00:03:19,320
That's right.

56
00:03:19,320 --> 00:03:24,800
Well, you know, when you're in day-to-day life, you don't always have a chance to like

57
00:03:24,800 --> 00:03:29,120
reflect on what the most moral action might be in that situation.

58
00:03:29,120 --> 00:03:31,120
Well, yeah.

59
00:03:31,120 --> 00:03:33,880
To sit there for now, we're thinking about whether you're going to give someone a transplant

60
00:03:33,880 --> 00:03:34,880
or so.

61
00:03:34,880 --> 00:03:35,880
Yeah.

62
00:03:35,880 --> 00:03:36,880
Right.

63
00:03:36,880 --> 00:03:37,880
You don't have time to think about these things.

64
00:03:37,880 --> 00:03:38,880
And I like, we're talking about ethics.

65
00:03:38,880 --> 00:03:42,280
I like how movies, especially a movie we just saw District 9 on, I don't know if you've

66
00:03:42,280 --> 00:03:43,280
seen that Nick yet.

67
00:03:43,280 --> 00:03:48,720
It ultimately comes out to be a very strong ethical movie.

68
00:03:48,720 --> 00:03:53,120
There's lots of questions amongst all this action and some comical scenes, there are

69
00:03:53,120 --> 00:03:58,560
some really ethical dilemmas in the movie, which I think is good that's promoted in a,

70
00:03:58,560 --> 00:04:00,360
it's a popular kind of meme.

71
00:04:00,360 --> 00:04:05,800
So is it infiltrating pop culture these days, ethics, like through movies like The Matrix,

72
00:04:05,800 --> 00:04:08,440
movies like District 9, is that the way to do it?

73
00:04:08,440 --> 00:04:10,440
Is our sound okay?

74
00:04:10,440 --> 00:04:11,440
Yeah.

75
00:04:11,600 --> 00:04:15,120
I think there's usually, yeah, a lot of movies have some kind of ethical message in them.

76
00:04:15,120 --> 00:04:20,240
I mean, even like the most named superhero movie usually makes some attempt at some kind

77
00:04:20,240 --> 00:04:21,880
of ethical situation.

78
00:04:21,880 --> 00:04:26,720
Well, I remember the most recent, The Dark Knight, the Batman movie, had a bunch of stuff

79
00:04:26,720 --> 00:04:27,720
in that.

80
00:04:27,720 --> 00:04:30,880
Like there was one scene I remember where the Joker has these two boats full of people,

81
00:04:30,880 --> 00:04:35,800
one's all prisoners and one's all just regular people and he's trying to get them to blow

82
00:04:35,800 --> 00:04:36,800
each other up or something.

83
00:04:36,800 --> 00:04:37,800
Right.

84
00:04:37,800 --> 00:04:38,800
Yeah.

85
00:04:38,840 --> 00:04:43,560
And then you see people getting ready to, getting a trigger, and then you actually see

86
00:04:43,560 --> 00:04:47,880
the criminal do one of the most ethical things and he throws it out, you know, we're the

87
00:04:47,880 --> 00:04:48,880
bad guys.

88
00:04:48,880 --> 00:04:49,880
Right.

89
00:04:49,880 --> 00:04:53,720
Yeah, so they're trying to, I mean, I guess it's the skillful means, is that right?

90
00:04:53,720 --> 00:04:56,800
The right director knows how to do it the right way, I suppose?

91
00:04:56,800 --> 00:04:57,800
Yeah.

92
00:04:57,800 --> 00:04:58,800
Right.

93
00:04:58,800 --> 00:04:59,800
Yeah.

94
00:04:59,800 --> 00:05:00,800
Okay.

95
00:05:00,800 --> 00:05:06,960
Well, so I guess, where else can we go with ethics?

96
00:05:06,960 --> 00:05:08,360
Ethics is a big thing.

97
00:05:08,360 --> 00:05:13,000
We don't have to abandon it so far, I mean, a lot of people get into serious arguments

98
00:05:13,000 --> 00:05:16,080
about ethics and when do we put in relativism?

99
00:05:16,080 --> 00:05:21,160
How big of a postmodern kind of world view do you adapt?

100
00:05:21,160 --> 00:05:24,800
What's healthy in your view before it goes to mushy, mushy, gushy, gushy?

101
00:05:24,800 --> 00:05:30,480
Well, I mean, that's a difficult question because you do have these striking examples

102
00:05:30,480 --> 00:05:34,440
of other cultures where things are completely different, like am I allowed, for example,

103
00:05:34,440 --> 00:05:41,720
to condemn someone, an Islamic extremist who kills their own daughter because she left

104
00:05:41,720 --> 00:05:45,920
the religion or something and I almost can't help condemning them, but on the other hand...

105
00:05:45,920 --> 00:05:50,280
That seems like an easier question to answer, I mean, when it's taking someone's life, but

106
00:05:50,280 --> 00:05:52,920
what about like, you know, the headscarves and whatnot?

107
00:05:52,920 --> 00:05:55,360
Do you think women should be explored dressed like women?

108
00:05:55,360 --> 00:06:02,360
Oh, yeah, well, that stuff, I mean, that's relatively minor, I mean, I don't have any

109
00:06:02,360 --> 00:06:04,760
huge objection to women wearing headscarves.

110
00:06:04,760 --> 00:06:11,120
The burqa is a little more up in the air because a lot of times the women wearing those things

111
00:06:11,120 --> 00:06:15,560
are not doing so their own, you know, they're not making a fashion statement, they have

112
00:06:15,560 --> 00:06:18,720
a man and a life enforcing this.

113
00:06:18,720 --> 00:06:23,800
Where was it in, was it Lebanon recently that a woman was wearing pants in public and she...

114
00:06:23,800 --> 00:06:26,360
Yeah, was sentenced to death wearing pants, right.

115
00:06:26,360 --> 00:06:28,360
Was it death or just lashings or something?

116
00:06:28,360 --> 00:06:33,840
No, it was like the lashing equivalent of a death sentence, like 40 lashings or something.

117
00:06:33,840 --> 00:06:34,840
Oh, yeah.

118
00:06:34,840 --> 00:06:37,640
There's a part of you that just says, what the fuck is going on?

119
00:06:37,640 --> 00:06:38,640
That's ridiculous.

120
00:06:38,640 --> 00:06:43,640
I think that's, I mean, but see, just if we can all agree that that's ridiculous, another

121
00:06:43,640 --> 00:06:48,600
moral question is, should we actually go to Lebanon invading it and actually try to change

122
00:06:48,600 --> 00:06:49,600
it?

123
00:06:49,600 --> 00:06:54,000
That's, I'll cover up with Professor Anton actually is the concept of, and you're going

124
00:06:54,000 --> 00:06:59,880
to get a lot of people hissing and moaning at this, a one-world type of governing system

125
00:06:59,880 --> 00:07:00,880
body.

126
00:07:00,880 --> 00:07:06,160
But it's also, to try to fix the problem would cause, at least initially, more violence and

127
00:07:06,160 --> 00:07:09,480
death than the problem itself.

128
00:07:09,480 --> 00:07:10,480
This is also seen in movies.

129
00:07:10,480 --> 00:07:12,360
I mean, more absolute power, would that corrupt?

130
00:07:12,360 --> 00:07:13,360
Absolutely.

131
00:07:13,360 --> 00:07:16,160
I mean, I think, I've seen a video where you've actually quoted that and tried to explain

132
00:07:16,160 --> 00:07:18,600
about that, but it just seems like, what do you do?

133
00:07:18,600 --> 00:07:23,480
This is just this dilemma, do we just let them be or do we go absolute, Ron Paul, libertarian,

134
00:07:23,960 --> 00:07:28,600
you know, you guys go for it, how about it, you know?

135
00:07:28,600 --> 00:07:33,480
So what, I mean, how do you deal with some of these questions where you see the truth,

136
00:07:33,480 --> 00:07:37,160
the grain of truth that they bring to the perspective?

137
00:07:37,160 --> 00:07:41,080
Like there's a party that nods, like, yeah, it makes sense, but at the same time, it conflicts.

138
00:07:41,080 --> 00:07:42,080
This is strange.

139
00:07:42,080 --> 00:07:43,080
Yeah.

140
00:07:43,080 --> 00:07:49,000
Well, let me ask you, Nikitin, do you think that there is in any way a good, a capital

141
00:07:49,000 --> 00:07:54,280
G good that's greater than any particular cultural good that sort of has authority over

142
00:07:54,280 --> 00:07:57,720
what any particular world you may think is good?

143
00:07:57,720 --> 00:08:00,480
Or do you think that that's just an illusion?

144
00:08:00,480 --> 00:08:01,640
I don't think so.

145
00:08:01,640 --> 00:08:03,200
I don't think that exists.

146
00:08:03,200 --> 00:08:08,240
I think good is a creation of our own minds and our own minds are, of course, running

147
00:08:08,240 --> 00:08:11,080
a lot of cultural software that are influencing it.

148
00:08:11,080 --> 00:08:17,760
I mean, I think there are some basic ideas that are so a part of who we are, biologically

149
00:08:17,760 --> 00:08:24,160
speaking, that pretty much all of us, with the exception of, say, sociopaths, have these

150
00:08:24,160 --> 00:08:31,880
intuitions and feelings, but I don't think there's like a good floating out in the way.

151
00:08:31,880 --> 00:08:32,880
Yeah, yeah, yeah.

152
00:08:32,880 --> 00:08:33,880
Right.

153
00:08:33,880 --> 00:08:34,880
Right.

154
00:08:34,880 --> 00:08:38,400
Well, I think someone else watching this might interpret that, like, you take the stance

155
00:08:38,400 --> 00:08:39,400
of amendum.

156
00:08:39,400 --> 00:08:42,680
He thinks there's an objective, you know, it's a fact of suffering, so not suffering

157
00:08:42,680 --> 00:08:44,600
would be objectively good for him.

158
00:08:44,600 --> 00:08:45,600
Right.

159
00:08:45,600 --> 00:08:50,000
And you try to say, well, that does a subjective spin, not that it's wrong, or an intersubjective

160
00:08:50,000 --> 00:08:55,320
spin, but he says, no, you're fucked-hearted, it has to be, it is an objective kind of thing.

161
00:08:55,320 --> 00:08:56,320
Yeah, you're right.

162
00:08:56,320 --> 00:08:57,320
Yeah.

163
00:08:57,320 --> 00:08:58,320
Amendum, he said suffering is fucking objective.

164
00:08:58,320 --> 00:09:03,320
You know, I've never been able to figure out what he means by that, because to me, it seems

165
00:09:03,320 --> 00:09:08,840
like suffering, pleasure, color, all of that is fairly subjective.

166
00:09:08,840 --> 00:09:11,640
So I can't even figure out what he's trying to say.

167
00:09:11,680 --> 00:09:17,840
I agree with the underlying message that he's trying to convey, just not the way he tries

168
00:09:17,840 --> 00:09:18,840
to convey it.

169
00:09:18,840 --> 00:09:24,880
I usually agree with the inclusions he draws, but the way he comes to conclusions is weird.

