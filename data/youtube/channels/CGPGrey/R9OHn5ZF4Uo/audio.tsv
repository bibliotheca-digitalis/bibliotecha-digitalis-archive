start	end	text
0	2960	On the internet, the algorithms are all around you.
2960	7280	You are watching this video because an algorithm brought it to you, among others, to click,
7280	10080	which you did, and the algorithm took note.
10080	13520	When you open the tweet book, A, the algorithm decides what you see.
13520	16960	When you search through your photos, A, the algorithm does the finding,
16960	18880	maybe even makes a little movie for you.
18880	21760	When you buy something, A, the algorithm sets the price,
21760	26000	and A, the algorithm is at your bank watching transactions for fraud.
26000	29680	The stock market is full of algorithms trading with algorithms.
29680	34320	Given this, you might want to know how these little algorithmic bots shaping your world work,
34320	36080	especially when they don't.
36080	38800	In ye olden days, humans built algorithmic bots
38800	42000	by giving them instructions the humans could explain.
42000	43760	If this, then that.
43760	49120	But many problems are just too big and hard for a human to write simple instructions for.
49120	51840	There's a gazillion financial transactions a second.
51840	53520	Which ones are fraudulent?
53520	56000	There's octillion videos on NetMeTube.
56000	58960	Which eight should the user see as recommendations?
58960	61600	Which shouldn't be allowed on the site at all?
61600	66080	For this airline seat, what is the maximum price this user will pay right now?
66080	68480	Algorithmic bots give answers to these questions.
68480	71840	Not perfect answers, but much better than a human could do.
71840	75760	But how these bots work exactly more and more, no one knows.
75760	77760	Not even the humans who built them.
77760	79760	Or built them, as we will see.
79760	83360	Now, companies that use these bots don't want to talk about how they work
83360	85760	because the bots are valuable employees.
85760	87200	Very, very valuable.
87200	90720	And how their brains are built is a fiercely guarded trade secret.
90720	94560	Right now, the cutting edge is most likely very I hope you like linear algebra,
94560	97360	but what the current hotness is on any particular site
97360	99840	and how the bots work is a bit, I don't know.
99840	101200	And always will be.
101200	105440	So let's talk about one of the more quaint but understandable ways bots can be built
105440	108320	without understanding how their brains work.
108320	111200	Say you want a bot that can recognize what is in a picture.
111200	113360	Is it a B or is it a 3?
113360	115680	It's easy for humans, even little humans,
115680	119760	but it's impossible to just tell a bot in bot language how to do it
119760	123600	because really we just know that's a B and that's a 3.
123600	127200	We can say in words what makes them different, but bots don't understand words.
127200	131040	And it's the wiring in our brains that makes it happen anyway.
131040	133680	While an individual neuron may be understood
133680	136720	and clusters of neurons' general purpose vaguely grasped,
136720	138400	the whole is beyond.
138400	139920	Nonetheless, it works.
139920	143360	So to get a bot that can do this sorting, you don't build it yourself.
143360	147120	You build a bot that builds bots and a bot that teaches bots.
147120	151600	These bots' brains are simpler, something a smart human programmer can make.
151600	155040	The builder bot builds bots, though it's not very good at it.
155040	159360	At first, it connects the wires and modules in the bot brains almost at random.
159360	164480	This leads to some very special student bots sent to teacher bot to teach.
164480	167600	Of course, teacher bot can't tell a B from a 3 either.
167600	171120	If the human could build teacher bot to do that, well then problem solved.
171120	174720	Instead, the human gives teacher bot a bunch of B photos and 3 photos
174720	176960	and an answer key to which is what.
176960	180640	Teacher bot can't teach, but teacher bot can test.
180640	183760	The adorkable student bots stick out their tongues, try very hard,
183760	185760	but they are bad at what they do.
185760	187120	Very, very bad.
187120	188880	And it's not their fault, really.
188880	190000	They were built that way.
190000	193520	Grades in hand, the student bots take a march of shame back to builder bot.
193520	197200	Those that did best are put to one side, the others recycled.
197200	199680	Builder bot still isn't good at building bots,
199680	203760	but now it takes those left and makes copies with changes and new combinations.
203760	205360	Back to school they go.
205360	208960	Teacher bot teaches or tests again, and builder bot builds again.
208960	210000	And again.
210000	210800	And again.
210800	214160	Now, a builder that builds at random and a teacher that doesn't teach just tests
214160	216560	and students who can't learn, they just are what they are,
216560	219680	in theory shouldn't work, but in practice it does.
219680	221520	Partly because in every iteration,
221520	224880	builder bot's slaughterhouse keeps the best and discards the rest.
224880	228240	And partly because teacher bot isn't overseeing an old-timey,
228240	230720	one-room schoolhouse with a dozen students,
230720	234400	but an infinite warehouse with thousands of students.
234400	237760	The test isn't ten questions, but a million questions.
237760	241520	And how many times does the test-build-test-loop repeat?
241520	243840	As many as necessary.
243840	246560	At first, students that survive are just lucky,
246560	250400	but by combining enough lucky bots and keeping only what works,
250400	253200	and randomly messing around with new copies of that,
253200	256480	eventually a student bot emerges that isn't lucky,
256480	259520	that can perhaps barely tell bees from threes.
259520	263280	As this bot is copied and changed, slowly the average test score rises,
263280	267600	and thus the grade needed to survive the next round gets higher and higher.
267600	271040	Keep this up, and eventually from the infinite warehouse slaughterhouse,
271040	274560	a student bot will emerge who can tell a bee from a three in a photo
274560	276720	it's never seen before pretty well.
276720	279760	But how the student bot does this neither the teacher bot,
279760	283120	nor the builder bot, nor the human overseer can understand.
283120	285440	Nor the student bot itself.
285440	288400	After keeping so many useful random changes,
288400	291360	the wiring in its head is incredibly complicated,
291360	294400	and while an individual line of code may be understood,
294400	297120	and clusters of code's general purpose vaguely grasp,
297120	298960	the whole is beyond.
298960	300560	Nonetheless, it works.
300560	304240	But this is frustrating, especially as the student bot is very good
304240	308000	at exactly only the kinds of questions it's been taught to.
308000	310560	It's great with photos, but useless with videos,
310560	313440	or baffled if the photos are upside down,
313440	317120	or things that are obviously not bees, it's confident are.
317120	320240	Since teacher bot can't teach, all the human overseer can do
320240	323120	is give it more questions to make the test even longer,
323120	326640	to include the kinds of questions the best bots get wrong.
326640	328560	This is important to understand.
328560	332560	It's a reason why companies are obsessed with collecting data.
332560	335760	More data equals longer tests equals better bots.
335760	338800	So when you get the are you human test on a website,
338800	341280	you are not only proving that you are human, hopefully,
341280	344720	but you are also helping to build the test to make bots that can read,
344720	347680	or count, or tell lakes from mountains, or horses from humans.
347680	350080	Seeing lots of questions about driving lately?
350080	352880	Hmm, what could that be building a test for?
352880	356320	Now figuring out what's in a photo, or on a sign, or filtering videos
356320	359200	requires humans to make correct enough tests.
359200	362400	But there is another kind of test that makes itself.
362400	364560	Tests on the humans.
364560	368080	For example, say entirely hypothetical NetMeTube
368080	371120	wanted users to keep watching as long as possible.
371120	374480	Well, how long a user stays on the site is easy to measure.
374480	378480	So Teacherbot gives each student bot a bunch of NetMeTube users to oversee.
378480	381440	The student bots watch what their user watches, looks at their files,
381440	384720	and do their best to pick the videos that keep the user on the site.
384720	387280	The longer the average, the higher their test score.
387280	389200	Build, test, repeat.
389200	392320	A million cycles later, there's a student bot who's pretty good
392320	394000	at keeping the users watching.
394000	396480	At least compared to what a human could build.
396480	400080	But when people ask how does the NetMeTube algorithm select videos,
400160	403920	once again, there isn't a great answer other than pointing to the bot,
403920	407360	and the user data it had access to, and most vitally,
407360	411600	how the human overseers direct Teacherbot to score the test.
411600	414720	That's what the bot is trying to be good at to survive.
414720	419360	But what the bot is thinking, or how it thinks it, is not really knowable.
419360	422960	All that's knowable is this student bot gets to be the algorithm
422960	429040	because it's 0.1% better than the previous bot at the test the humans designed.
429040	431440	So everywhere on the internet, behind the scenes,
431440	433680	there are tests to increase user interaction,
433680	437120	or set prices just right to maximize revenue,
437120	439520	or pick the posts from all your friends you'll like the most,
439520	442080	or articles people will share the most, or whatever.
442080	443760	If it's testable, it's teachable.
443760	444800	Well, teachable.
444800	447200	And a student bot will graduate from the warehouse
447200	449840	to be the algorithm of its domain.
449840	451440	At least, for a little while.
451440	453600	We're used to the idea that the tools we use,
453600	456240	even if we don't understand them, someone does.
456320	459760	But with our machines that learn, we are increasingly in a position
459760	462400	where we use tools, or are used by tools,
462400	465680	that no one, not even their creators, understand.
465680	469200	We can only hope to guide them with the tests we make.
469200	470880	And we need to get comfortable with that,
470880	475760	as our algorithmic bot buddies are all around and not going anywhere.
478160	479840	Okay, the bots are watching.
480640	481520	You know what's coming.
482240	488320	This is where I need to ask you to like, comment, and subscribe.
489440	490160	And bell me.
491280	492640	And share on the tweet book.
493680	494880	The algorithm is watching.
495760	499040	It won't show people the video unless you do this.
501040	502640	Look what you've reduced me to, bots.
504160	505040	What do you want?
505040	506320	Do you want watch time?
506320	507200	Is that what you want?
508000	508400	Fine.
508400	514320	Hey guys, did you know I also have podcasts you can listen to?
514320	516400	Maybe even just in the background
516400	520000	while you're tidying up your all room for hours or whatever.
520560	523440	There's hours of audio entertainment for you
523440	526960	and watch time for the bots overseeing your actions.
526960	528720	Go ahead and take a click.
528720	529680	Entertain yourself.
530400	532880	Help me help the bots.
